{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "382c4ec2-8213-432c-8110-4c994c22cc02",
   "metadata": {},
   "source": [
    "# preprocess LOWZ target photometry and spectroscopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b074593-8b37-47d2-bf25-034b84d24f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import astropy.table as aTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "612b5c01-35ff-49bd-8575-42a673b2920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from provabgs import desi as DESI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87dd5bea-1043-46f0-aac7-dde831be833f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.preview in file /global/homes/c/chahah/.conda/envs/gqp/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key mathtext.fallback_to_cm in file /global/homes/c/chahah/.conda/envs/gqp/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.jpeg_quality in file /global/homes/c/chahah/.conda/envs/gqp/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key keymap.all_axes in file /global/homes/c/chahah/.conda/envs/gqp/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_path in file /global/homes/c/chahah/.conda/envs/gqp/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_args in file /global/homes/c/chahah/.conda/envs/gqp/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "# -- plotting -- \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "mpl.rcParams['axes.linewidth'] = 1.5\n",
    "mpl.rcParams['axes.xmargin'] = 1\n",
    "mpl.rcParams['xtick.labelsize'] = 'x-large'\n",
    "mpl.rcParams['xtick.major.size'] = 5\n",
    "mpl.rcParams['xtick.major.width'] = 1.5\n",
    "mpl.rcParams['ytick.labelsize'] = 'x-large'\n",
    "mpl.rcParams['ytick.major.size'] = 5\n",
    "mpl.rcParams['ytick.major.width'] = 1.5\n",
    "mpl.rcParams['legend.frameon'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f116291-9502-45e2-a9f9-350a66aa6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_dir = '/global/cfs/cdirs/desi/users/chahah/provabgs/lowz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d20177-2592-4b88-b657-9d9762118d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowz_targ = aTable.Table.read(os.path.join(dat_dir, 'provabgs_lowz_targets.fits'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5a10ad2-0819-4a13-ba79-91da024d74f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121277 lowz targets\n"
     ]
    }
   ],
   "source": [
    "print('%i lowz targets' % len(lowz_targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2be0d8d-c950-4969-ab05-1025668e7dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lowztarget_coadd(healpix, targetid): \n",
    "    # find healpix coadd file with LOWZ target\n",
    "    \n",
    "    redux = ['fuji', 'guadalupe']\n",
    "    survey = ['sv1', 'sv3', 'main']\n",
    "    \n",
    "    for r in redux: \n",
    "        for s in survey: \n",
    "            for b in ['dark', 'bright']: \n",
    "                fcoadd = os.path.join('/global/cfs/cdirs/desi/spectro/redux/', \n",
    "                                      '%s/healpix/%s/%s/%s/%i/coadd-%s-%s-%i.fits' % (r, s, b, str(healpix)[:-2], healpix, s, b, healpix))\n",
    "                if os.path.isfile(fcoadd):\n",
    "                    coadd = aTable.Table.read(fcoadd)\n",
    "    \n",
    "                    if np.sum(coadd['TARGETID'] == targetid): \n",
    "                        return fcoadd\n",
    "                              \n",
    "    raise ValueError(\"couldn't find target\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c1cfdc-168d-4ed6-a987-3818d60aa91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 of 25\n",
      "\t 35000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: hdu= was not specified but multiple tables are present, reading in first available table (hdu=1) [astropy.io.fits.connect]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 35100\n",
      "\t 35200\n",
      "\t 35300\n",
      "\t 35400\n",
      "\t 35500\n",
      "\t 35600\n",
      "\t 35700\n",
      "\t 35800\n",
      "\t 35900\n",
      "\t 36000\n",
      "\t 36100\n",
      "\t 36200\n",
      "\t 36300\n",
      "\t 36400\n",
      "\t 36500\n",
      "\t 36600\n",
      "\t 36700\n",
      "\t 36800\n",
      "\t 36900\n",
      "\t 37000\n",
      "\t 37100\n",
      "\t 37200\n",
      "\t 37300\n",
      "\t 37400\n",
      "\t 37500\n",
      "\t 37600\n",
      "\t 37700\n",
      "\t 37800\n",
      "\t 37900\n",
      "\t 38000\n",
      "\t 38100\n",
      "\t 38200\n",
      "\t 38300\n",
      "\t 38400\n",
      "\t 38500\n",
      "\t 38600\n",
      "\t 38700\n",
      "\t 38800\n",
      "\t 38900\n",
      "\t 39000\n",
      "\t 39100\n",
      "\t 39200\n",
      "\t 39300\n",
      "\t 39400\n",
      "\t 39500\n",
      "\t 39600\n",
      "\t 39700\n",
      "\t 39800\n",
      "\t 39900\n",
      "8 of 25\n",
      "\t 40000\n",
      "\t 40100\n",
      "\t 40200\n",
      "\t 40300\n",
      "\t 40400\n",
      "\t 40500\n",
      "\t 40600\n",
      "\t 40700\n",
      "\t 40800\n",
      "\t 40900\n",
      "\t 41000\n",
      "\t 41100\n",
      "\t 41200\n",
      "\t 41300\n",
      "\t 41400\n",
      "\t 41500\n",
      "\t 41600\n",
      "\t 41700\n",
      "\t 41800\n",
      "\t 41900\n",
      "\t 42000\n",
      "\t 42100\n",
      "\t 42200\n",
      "\t 42300\n",
      "\t 42400\n",
      "\t 42500\n",
      "\t 42600\n",
      "\t 42700\n",
      "\t 42800\n",
      "\t 42900\n",
      "\t 43000\n",
      "\t 43100\n",
      "\t 43200\n",
      "\t 43300\n",
      "\t 43400\n",
      "\t 43500\n",
      "\t 43600\n",
      "\t 43700\n",
      "\t 43800\n",
      "\t 43900\n",
      "\t 44000\n",
      "\t 44100\n",
      "\t 44200\n",
      "\t 44300\n",
      "\t 44400\n",
      "\t 44500\n",
      "\t 44600\n",
      "\t 44700\n",
      "\t 44800\n",
      "\t 44900\n",
      "9 of 25\n",
      "\t 45000\n",
      "\t 45100\n",
      "\t 45200\n",
      "\t 45300\n",
      "\t 45400\n",
      "\t 45500\n",
      "\t 45600\n",
      "\t 45700\n",
      "\t 45800\n",
      "\t 45900\n",
      "\t 46000\n",
      "\t 46100\n",
      "\t 46200\n",
      "\t 46300\n",
      "\t 46400\n",
      "\t 46500\n",
      "\t 46600\n",
      "\t 46700\n",
      "\t 46800\n",
      "\t 46900\n",
      "\t 47000\n",
      "\t 47100\n",
      "\t 47200\n",
      "\t 47300\n",
      "\t 47400\n",
      "\t 47500\n",
      "\t 47600\n",
      "\t 47700\n",
      "\t 47800\n",
      "\t 47900\n",
      "\t 48000\n",
      "\t 48100\n",
      "\t 48200\n",
      "\t 48300\n",
      "\t 48400\n",
      "\t 48500\n",
      "\t 48600\n",
      "\t 48700\n",
      "\t 48800\n",
      "\t 48900\n",
      "\t 49000\n",
      "\t 49100\n",
      "\t 49200\n",
      "\t 49300\n",
      "\t 49400\n",
      "\t 49500\n",
      "\t 49600\n",
      "\t 49700\n",
      "\t 49800\n",
      "\t 49900\n",
      "10 of 25\n",
      "\t 50000\n",
      "\t 50100\n",
      "\t 50200\n",
      "\t 50300\n",
      "\t 50400\n",
      "\t 50500\n",
      "\t 50600\n",
      "\t 50700\n",
      "\t 50800\n",
      "\t 50900\n",
      "\t 51000\n",
      "\t 51100\n",
      "\t 51200\n",
      "\t 51300\n",
      "\t 51400\n",
      "\t 51500\n",
      "\t 51600\n",
      "\t 51700\n",
      "\t 51800\n",
      "\t 51900\n",
      "\t 52000\n",
      "\t 52100\n",
      "\t 52200\n",
      "\t 52300\n",
      "\t 52400\n",
      "\t 52500\n",
      "\t 52600\n",
      "\t 52700\n",
      "\t 52800\n",
      "\t 52900\n",
      "\t 53000\n",
      "\t 53100\n",
      "\t 53200\n",
      "\t 53300\n",
      "\t 53400\n",
      "\t 53500\n",
      "\t 53600\n",
      "\t 53700\n",
      "\t 53800\n",
      "\t 53900\n",
      "\t 54000\n",
      "\t 54100\n",
      "\t 54200\n",
      "\t 54300\n",
      "\t 54400\n"
     ]
    }
   ],
   "source": [
    "for ii in range(7, 25): \n",
    "    print('%i of 25' % ii)\n",
    "    \n",
    "    targid = []\n",
    "    f_photo, i_photo = [], [] \n",
    "    w_spec, f_spec, i_spec = [], [], [] \n",
    "    f_fib, sig_f_fib = [], [] \n",
    "    redshifts = [] \n",
    "\n",
    "    for i in range(5000 * ii, np.min([5000 * (ii+1), len(lowz_targ)])): \n",
    "        if i % 100 == 0: print('\\t %i' % i)\n",
    "        fcoadd = find_lowztarget_coadd(lowz_targ['HEALPIX'][i], lowz_targ['TARGETID'][i])\n",
    "        frrock = fcoadd.replace('coadd', 'redrock')\n",
    "\n",
    "        coadd = aTable.Table.read(fcoadd)\n",
    "        rrock = aTable.Table.read(frrock)\n",
    "        \n",
    "        is_target = (coadd['TARGETID'] == lowz_targ['TARGETID'][i])\n",
    "\n",
    "        spec = DESI.readDESIspec(fcoadd)\n",
    "\n",
    "        # spectra\n",
    "        w_obs = np.concatenate([spec['wave_b'], spec['wave_r'], spec['wave_z']])\n",
    "        f_obs = np.concatenate([spec['flux_b'], spec['flux_r'], spec['flux_z']],\n",
    "                axis=1)\n",
    "        i_obs = np.concatenate([spec['ivar_b'], spec['ivar_r'], spec['ivar_z']],\n",
    "                axis=1)\n",
    "\n",
    "        # sort the wavelength\n",
    "        isort = np.argsort(w_obs)\n",
    "        w_obs = w_obs[isort]\n",
    "        f_obs = f_obs[is_target,:][:,isort]\n",
    "        i_obs = i_obs[is_target,:][:,isort]\n",
    "\n",
    "        # photometry (de-redden)\n",
    "        coadd = coadd[is_target]\n",
    "        # assign photsys\n",
    "        photsys = 'S'\n",
    "        if coadd['TARGET_DEC'] > 32.375: photsys = 'N' \n",
    "        \n",
    "        trans_g = DESI.mwdust_transmission(coadd['EBV'], 'g',\n",
    "                np.array([photsys]).astype(str),\n",
    "                match_legacy_surveys=False)\n",
    "        trans_r = DESI.mwdust_transmission(coadd['EBV'], 'r',\n",
    "                np.array([photsys]).astype(str),\n",
    "                match_legacy_surveys=False)\n",
    "        trans_z = DESI.mwdust_transmission(coadd['EBV'], 'z',\n",
    "                np.array([photsys]).astype(str),\n",
    "                match_legacy_surveys=False)\n",
    "\n",
    "        flux_g = coadd['FLUX_G'] / trans_g\n",
    "        flux_r = coadd['FLUX_R'] / trans_r\n",
    "        flux_z = coadd['FLUX_Z'] / trans_z\n",
    "        fiberflux_r = coadd['FIBERFLUX_R'] / trans_r\n",
    "\n",
    "        #list(coadd['FLUX_G', 'FLUX_R', 'FLUX_Z'].as_array())).copy()\n",
    "        photo_flux = np.array([flux_g, flux_r, flux_z]).T\n",
    "        photo_ivar = np.array(list(coadd['FLUX_IVAR_G', 'FLUX_IVAR_R', 'FLUX_IVAR_Z'].as_array())).copy()\n",
    "\n",
    "        # fiber flux fraction estimate\n",
    "        f_fiber = coadd['FIBERFLUX_R'] / coadd['FLUX_R']\n",
    "        sigma_f_fiber = f_fiber * coadd['FLUX_IVAR_R']**-0.5\n",
    "\n",
    "        # redshift\n",
    "        zred = rrock['Z'][is_target]\n",
    "\n",
    "        f_photo.append(photo_flux)\n",
    "        i_photo.append(photo_ivar)\n",
    "\n",
    "        w_spec.append(w_obs)\n",
    "        f_spec.append(f_obs)\n",
    "        i_spec.append(i_obs)\n",
    "\n",
    "        f_fib.append(f_fiber)\n",
    "        sig_f_fib.append(sigma_f_fiber)\n",
    "        \n",
    "        redshifts.append(zred)\n",
    "        targid.append(lowz_targ['TARGETID'][i])\n",
    "    \n",
    "    fh5 = h5py.File(os.path.join(dat_dir, 'lowz.obs.%iof25.hdf5' % ii), 'w')\n",
    "    fh5.create_dataset('TARGETID', data=np.array(targid).astype(int))\n",
    "                       \n",
    "    fh5.create_dataset('photo_flux', data=np.array(f_photo))\n",
    "    fh5.create_dataset('photo_ivar', data=np.array(i_photo))\n",
    "    \n",
    "    fh5.create_dataset('spec_wave', data=np.array(w_spec))\n",
    "    fh5.create_dataset('spec_flux', data=np.array(f_spec))\n",
    "    fh5.create_dataset('spec_ivar', data=np.array(i_spec))\n",
    "    \n",
    "    fh5.create_dataset('fiber_flux', data=np.array(f_fib))\n",
    "    fh5.create_dataset('fiber_sigma_flux', data=np.array(sig_f_fib))\n",
    "    \n",
    "    fh5.create_dataset('redshift', data=np.array(redshifts))\n",
    "    fh5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d437ea-dfab-4f17-ae4f-e9a65d10930e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gqp",
   "language": "python",
   "name": "gqp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
